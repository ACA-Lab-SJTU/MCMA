{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shy/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "num_cores=4\n",
    "num_CPU=1\n",
    "num_GPU=0\n",
    "config=tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                     inter_op_parallelism_threads=num_cores,\n",
    "                     allow_soft_placement=True,\n",
    "                     gpu_options=tf.GPUOptions(allow_growth=True),\n",
    "                     device_count={'CPU':num_CPU,'GPU':num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD,RMSprop,Adamax,Adam,Adagrad\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.utils import np_utils,generic_utils\n",
    "from keras import metrics\n",
    "import error\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametres\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=4\n",
    "error_bound=0.05\n",
    "net_A=[2,4,4,1]\n",
    "net_C=[2,4,2]\n",
    "\n",
    "epochA=2\n",
    "epochC=5\n",
    "batch_size=256\n",
    "\n",
    "error_type=\"absolute_error\"\n",
    "\n",
    "def error_compare(error_type):\n",
    "    if (error_type==\"absolute_error\"):\n",
    "        return error.absolute_error\n",
    "    else:\n",
    "        return error.relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_measure=error_compare(error_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data processing\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    try:\n",
    "        if (len(data.shape)==1):\n",
    "            return data.reshape((data.shape[0],1))\n",
    "        else:\n",
    "            return data\n",
    "    except:\n",
    "        print(\"Error! data is not a numpy object,format_data failed!\")\n",
    "        exit(0)\n",
    "\n",
    "def load_data(app_name):\n",
    "    x_train=np.loadtxt('../data/'+app_name+'/train.x')\n",
    "    y_train=np.loadtxt('../data/'+app_name+'/train.y')\n",
    "    x_test=np.loadtxt('../data/'+app_name+'/test.x')\n",
    "    y_test=np.loadtxt('../data/'+app_name+'/test.y')\n",
    "    return format_data(x_train),format_data(y_train),format_data(x_test),format_data(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on outputs\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_accept(error_bound):\n",
    "    def accept(v0,v1):\n",
    "        return error_measure([v0],[v1])<=error_bound\n",
    "    return accept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accelerator & Classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AcceleratorModel(net_list,type=0):\n",
    "    if (len(net_list)<2):\n",
    "        print('Error! input accelerator net structure is wrong!')\n",
    "        exit(0)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(net_list[1],input_shape=(net_list[0],)))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    for i in net_list[2:]:\n",
    "        model.add(Dense(i))\n",
    "        model.add(Activation('tanh'))\n",
    "        \n",
    "    prop=[RMSprop(0.01),RMSprop(0.008),RMSprop(0.006)]\n",
    "    #prop=[Adagrad(),Adagrad(),Adagrad()]\n",
    "    model.compile(loss='mse',optimizer=prop[type],metrics=[metrics.mse]) #不同application训练一定要不同loss function吗？待查\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierModel(net_list):\n",
    "    if (len(net_list)<2):\n",
    "        print('Error! input classifier net structure is wrong!')\n",
    "        exit(0)\n",
    "    model=Sequential()\n",
    "    model.add(Dense((net_list[1]),input_shape=(net_list[0],)))\n",
    "    if (len(net_list)>2):\n",
    "        model.add(Activation('tanh'))\n",
    "        for i in net_list[2:-1]:\n",
    "            model.add(Dense(net_list[i]))\n",
    "            model.add(Activation('tanh'))\n",
    "        model.add(Dense(net_list[-1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=RMSprop(0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Block\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(app_name,iteration,error_bound):\n",
    "    #Load data\n",
    "    x_train_origin,y_train_origin,x_test,y_test=load_data(app_name) #numpy type\n",
    "    print (\"Training data shape:\",x_train_origin.shape,y_train_origin.shape)#Print the input shape, compare with the net_A and net_C, \n",
    "    print('Testing data shape:',x_test.shape,y_test.shape)                  #check whether they match each other\n",
    "    \n",
    "    #Setting about approximator and classifier(There may be more than one Approximator, refer to acceleratorModel())\n",
    "    A=[AcceleratorModel(net_A,i)for i in range(3)]\n",
    "    C=ClassifierModel(net_C)\n",
    "    print(\"The Model A:\")\n",
    "    A[0].summary()\n",
    "    print(\"The Model C:\")\n",
    "    C.summary()\n",
    "    \n",
    "    \n",
    "    #每一个iteration：\n",
    "    #1.用上一轮的数据训练A（Using all data in train set in the 1st iteration）\n",
    "    #2.用所有Input做输入，predict A的output（这样能保证之前没有训练到的数据有加入训练数据的机会）\n",
    "    #3.A的输出和标准output比较，得出error，进而得出整个train数据集每一个数据能不能用A跑的label，用这个label训练C。\n",
    "    #4.让C对整个trainset进行预测，得到predictC。结合predictA和predictC产生下一个iteration的用于训练A的data（*算法）\n",
    "    #5.evaluate部分\n",
    "    \n",
    "    x_train=x_train_origin #第一轮训练A的数据\n",
    "    y_train=y_train_origin\n",
    "    for i in range(iteration):\n",
    "        \n",
    "        A[0].fit(x_train,y_train,epochs=epochA,batch_size=batch_size,verbose=1) #Train A\n",
    "        \n",
    "        predictA=A[0].predict(x_train_origin) #Predict for A on x_train\n",
    "        \n",
    "        labelA=np.array([error_measure([predictA[i]],[y_train_origin[i]])<=error_bound for i in range(len(predictA))])\n",
    "        \n",
    "        print labelA.shape\n",
    "        print labelA\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training data shape:', (70000, 2), (70000, 1))\n",
      "('Testing data shape:', (30000, 2), (30000, 1))\n",
      "The Model A:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The Model C:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "70000/70000 [==============================] - 4s 53us/step - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 2/2\n",
      "70000/70000 [==============================] - 3s 37us/step - loss: 0.0025 - mean_squared_error: 0.0025\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-40469fadc71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bessel_Jnu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-581e21b60d79>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(app_name, iteration, error_bound)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpredictA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_origin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Predict for A on x_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlabelA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0merror_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train_origin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0merror_bound\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlabelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "main('bessel_Jnu',1,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

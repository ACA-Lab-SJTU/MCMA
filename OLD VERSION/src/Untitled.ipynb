{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, kernel_initializer=\"uniform\", input_dim=6)`\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, kernel_initializer=\"uniform\")`\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\")`\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, kernel_initializer=\"uniform\", input_dim=6)`\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"uniform\")`\n",
      "/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackscholes_it10_eb0.05_ct2_epA100_epC100_bsA128_bsC128_netA6_8_8_1_netC6_8_2\n",
      "start training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94bddbd08fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0mbatch_sizeC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoose_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizeA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizeC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-94bddbd08fd8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(app_name, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mtrain_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoose_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizeA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizeC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0mapp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blackscholes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-94bddbd08fd8>\u001b[0m in \u001b[0;36mtrain_iteration\u001b[0;34m(A, C, X0, Y0, X1, Y1, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C, get_name)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# train accelerator with the current data(X0, Y0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_now\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_now\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_sizeA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# get the result of accelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/devil/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import error\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# set GPU memory \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   \n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "def AcceleratorModel(net_list):\n",
    "    if len(net_list) < 2:\n",
    "        print 'ERROR! input net structrue is wrong!'\n",
    "        exit(0)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(net_list[1], input_dim=net_list[0], init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in net_list[2:]:\n",
    "        model.add(Dense(i, init='uniform'))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def ClassiferModel(net_list):\n",
    "    if len(net_list) < 2:\n",
    "        print 'ERROR! input net structrue is wrong!'\n",
    "        exit(0)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(net_list[1], input_dim=net_list[0], init='uniform'))\n",
    "    \n",
    "    if len(net_list) > 2:\n",
    "        model.add(Activation('relu'))\n",
    "        for i in net_list[2:-1]:\n",
    "            model.add(Dense(i, init='uniform'))\n",
    "            model.add(Activation('relu'))\n",
    "        model.add(Dense(net_list[-1], init='uniform'))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def format_data(data):\n",
    "    try:\n",
    "        return data.reshape((data.shape[0], 1)) if len(data.shape) == 1 else data\n",
    "    except AttributeError as e:\n",
    "        print 'ERROR! data is not a numpy object, format_data failed!'\n",
    "        exit(0)\n",
    "\n",
    "def load_data(app_name):\n",
    "    X0 = np.loadtxt('../data/' + app_name + '/train.x')\n",
    "    Y0 = np.loadtxt('../data/' + app_name + '/train.y')\n",
    "    X1 = np.loadtxt('../data/' + app_name + '/test.x')\n",
    "    Y1 = np.loadtxt('../data/' + app_name + '/test.y')\n",
    "    return format_data(X0), format_data(Y0), format_data(X1), format_data(Y1)\n",
    "\n",
    "def gen_accept(re_bound):\n",
    "    def accept(v0, v1):\n",
    "        return error.relative_error(v0, v1) <= re_bound\n",
    "    return accept\n",
    "\n",
    "def choose_flag(shrink_type):\n",
    "    return [lambda a, c: a or c,\n",
    "            lambda a, c: c,\n",
    "            lambda a, c: a,\n",
    "            lambda a, c: a and c,\n",
    "            lambda a, c: 1][shrink_type]\n",
    "\n",
    "def gen_evaluate(X, Y, accept):\n",
    "    N = len(X)\n",
    "    def evaluate(A, C):\n",
    "        # accelerator results \n",
    "        acc = A.predict(X)\n",
    "        # classification by C and truly \n",
    "        cls_c = [1 if v[1] > v[0] else 0 for v in C.predict(X)]\n",
    "        cls_t = [accept(Y[i], acc[i]) for i in xrange(N)] # to bool\n",
    "        # relatvie error for all test data\n",
    "        re = [error.relative_error(Y[i], acc[i]) for i in xrange(N)]\n",
    "        re_c = [error.relative_error(Y[i], acc[i]) for i in xrange(N) if cls_c[i]]\n",
    "\n",
    "        # accuracy of C, recall of C\n",
    "        accuracy_of_C = sum([1.0 if cls_t[i] == cls_c[i] else 0 for i in xrange(N)]) / float(1e-10 + N)\n",
    "        recall_of_C = sum([1.0 if cls_t[i] and cls_c[i] else 0 for i in xrange(N)]) / float(1e-10 + sum([1 if v else 0 for v in cls_t]))\n",
    "\n",
    "        # invocation of C, invocation truly\n",
    "        invocation_of_C = float(sum([1 if v else 0 for v in cls_c])) / float(1e-10 + N)\n",
    "        invocation_truly = float(sum([1 if v else 0 for v in cls_t])) / float(1e-10 + N)\n",
    "\n",
    "        # re of A, re of A with C\n",
    "        mean_relative_error_of_A = sum(re) / float(1e-10 + len(re))\n",
    "        mean_relative_error_of_A_with_C = sum(re_c) / (1e-10 + len(re_c))\n",
    "\n",
    "        return {\n",
    "            'accuracy_of_C': accuracy_of_C,\n",
    "            'recall_of_C': recall_of_C,\n",
    "            'invocation_of_C': invocation_of_C,\n",
    "            'invocation_truly': invocation_truly,\n",
    "            'mean_relative_error_of_A': mean_relative_error_of_A,\n",
    "            'mean_relative_error_of_A_with_C': mean_relative_error_of_A_with_C\n",
    "        }\n",
    "\n",
    "    return evaluate\n",
    "\n",
    "def get_output_name(app_name, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C):\n",
    "    def get_name(iteration):\n",
    "        output_name = '{}_it{}_eb{}_ct{}_epA{}_epC{}_bsA{}_bsC{}_netA{}_netC{}'.format(app_name, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, '_'.join([str(x) for x in net_A]), '_'.join([str(x) for x in net_C]))\n",
    "        return output_name\n",
    "    return get_name\n",
    "\n",
    "def train_iteration(A, C, X0, Y0, X1, Y1, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C, get_name):\n",
    "    print 'start training'\n",
    "    accept = gen_accept(error_bound)\n",
    "    evaluate = gen_evaluate(X1, Y1, accept)\n",
    "    choose = choose_flag(choose_type)\n",
    "\n",
    "    X_origin = X0.copy()\n",
    "    Y_origin = Y0.copy()\n",
    "    X_now = X0.copy()\n",
    "    Y_now = Y0.copy()\n",
    "\n",
    "    f_results = open('../results/iteration/{}.csv'.format(get_name(iteration)), 'w')\n",
    "\n",
    "    keys = []\n",
    "    results = []\n",
    "\n",
    "    for index in range(iteration):\n",
    "        if len(X_now) == 0:\n",
    "            print 'No training data, end!'\n",
    "            break\n",
    "\n",
    "        # train accelerator with the current data(X0, Y0)\n",
    "        A.fit(X_now, Y_now, nb_epoch=epochA, batch_size=batch_sizeA, verbose=0)\n",
    "\n",
    "        # get the result of accelerator\n",
    "        acc = A.predict(X_origin)\n",
    "\n",
    "        # generate the truly classification\n",
    "        cls_t = [accept(Y_origin[i], acc[i]) for i in xrange(len(X_origin))]\n",
    "\n",
    "        print len([1 for i in cls_t if i])\n",
    "\n",
    "        # train the Classifer with X_origin, cls_t\n",
    "        Y_cls = np.array([1 if v else 0 for v in cls_t]).reshape((len(cls_t), 1))\n",
    "        Y_cls = np_utils.to_categorical(Y_cls, 2)\n",
    "        \n",
    "        C.fit(X_origin, Y_cls, nb_epoch=epochC, batch_size=batch_sizeC, show_accuracy=True, verbose=0)\n",
    "\n",
    "        # get the classifer result of origin data\n",
    "        cls_c = [1 if v[1] > v[0] else 0 for v in C.predict(X_origin)]\n",
    "        print len([1 for i in cls_c if i])\n",
    "\n",
    "        # generate the next X_now, Y_now\n",
    "\n",
    "        X_now = np.array([X_origin[i] for i in xrange(len(X_origin)) if choose(cls_t[i], cls_c[i])])\n",
    "        Y_now = np.array([Y_origin[i] for i in xrange(len(X_origin)) if choose(cls_t[i], cls_c[i])])\n",
    "\n",
    "        # save weights\n",
    "        A.save_weights('../weights/iteration/A_{}.weights'.format(get_name(index)), overwrite=True)\n",
    "        C.save_weights('../weights/iteration/C_{}.weights'.format(get_name(index)), overwrite=True)\n",
    "\n",
    "        # save this iteration results\n",
    "        item = {'iteration':index}\n",
    "        item.update(evaluate(A, C))\n",
    "        print item\n",
    "        if len(results) == 0:\n",
    "            keys = item.keys()\n",
    "            f_results.write(','.join(keys) + '\\n')\n",
    "        results.append(item)\n",
    "        f_results.write(','.join([str(item[v]) for v in keys]) + '\\n')\n",
    "        f_results.flush()\n",
    "\n",
    "    f_results.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main(app_name, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C):\n",
    "    X0, Y0, X1, Y1 = load_data(app_name)\n",
    "\n",
    "    A = AcceleratorModel(net_A)\n",
    "\n",
    "    C = ClassiferModel(net_C)\n",
    "\n",
    "    get_name = get_output_name(app_name, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C)\n",
    "\n",
    "    print get_name(iteration)\n",
    "    \n",
    "    train_iteration(A, C, X0, Y0, X1, Y1, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C, get_name)\n",
    "\n",
    "app_name = 'blackscholes'\n",
    "net_A = [6, 8, 8, 1]\n",
    "net_C = [6, 8, 2]\n",
    "error_bound = 0.05\n",
    "choose_type = 2\n",
    "epochA = 100\n",
    "epochC = 100\n",
    "batch_sizeA = 128\n",
    "batch_sizeC = 128\n",
    "iteration = 10\n",
    "main(app_name, iteration, error_bound, choose_type, epochA, epochC, batch_sizeA, batch_sizeC, net_A, net_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
